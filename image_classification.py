# -*- coding: utf-8 -*-
"""IMAGE CLASSIFICATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Um6-6n0BUFngeNmL8o1YRXaJBBBnqN6K

###Importing Libraries###
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf

from tensorflow.keras.datasets import mnist, fashion_mnist
from tensorflow.keras.utils import to_categorical # Import from tensorflow.keras.utils
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Softmax # For CNN
from tensorflow.keras.layers import Dropout, BatchNormalization, Activation       # For MLP
from tensorflow.keras.optimizers import Adam                                      # For Optimization
from tensorflow.keras.preprocessing.image import ImageDataGenerator               # Image Data Generator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model

"""###Loading Dataset###

**Importing and Loading Dataset**
"""

#
(X_train, y_train), (X_test, y_test) = mnist.load_data()
(X_train_f, y_train_f), (X_test_f, y_test_f) = fashion_mnist.load_data()

"""**Shape of each dataset**"""

print("MNIST DATASET \n","the shape of X_train is: {} \n and y_train is: {} \n and the shape of X_test is: {} \n and the shape of y_test is: {}".format(X_train.shape, y_train.shape, X_test.shape, y_test.shape))
print("FASHIONMNIST DATASET \n","the shape of X_train is: {} \n and y_train is: {} \n and the shape of X_test is: {} \n and the shape of y_test is {}".format(X_train_f.shape, y_train_f.shape, X_test_f.shape, y_test_f.shape))

"""(60000 , 28, 28) or (10000, 28, 28) means 60000 or 10000 images with image size of 28 X 28 pixel.

###Visualisation###
"""

#Visualisation on MNIST
plt.figure(figsize=(10,4))
for i in range(9):
    plt.subplot(1,9,i+1)
    plt.imshow(X_train[i], cmap='gray')
    plt.title(f"Label: {y_train[i]}")
    plt.axis('off')
    plt.suptitle("MNIST DATASET")
plt.show()

#Visualisation on FashionMNIST
plt.figure(figsize=(10,4))
for i in range(9):
    plt.subplot(1,9,i+1)
    plt.imshow(X_train_f[i], cmap='gray')
    plt.title(f"Label: {y_train_f[i]}")
    plt.axis('off')
    plt.suptitle("FashionMNIST DATASET")
plt.show()

# MNIST Hand written Datasets Visualisation
X_class_num = []
n_rows = 10
n_cols = 7
fig, axes = plt.subplots(nrows = n_rows, ncols=n_cols, figsize=(10,10))
fig.tight_layout()

for i in range(n_cols):
  for j in range(n_rows):
    x_select = X_train[y_train == j]
    axes[j][i].imshow(x_select[random.randint(0,len(x_select-1)),:,:], cmap='gray')
    axes[j][i].axis('off')

    if i == 3:
      axes[j][i].set_title(str(j))
      X_class_num.append(len(x_select))
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(0,10), X_class_num)
plt.xlabel("num of class of MNIST Hand written datasets")
plt.ylabel("num of samples")
plt.title("Distribution of MNIST Hand written datasets")
plt.show()

# FASHION MNIST DATA VISUALISATION
X_class_num = []
n_rows = 10
n_cols = 7
fig, axes = plt.subplots(nrows = n_rows, ncols=n_cols, figsize=(10,10))
fig.tight_layout()

for i in range(n_cols):
  for j in range(n_rows):
    x_select = X_train_f[y_train_f == j]
    axes[j][i].imshow(x_select[random.randint(0,len(x_select-1)),:,:], cmap='gray')
    axes[j][i].axis('off')

    if i == 3:
      axes[j][i].set_title(str(j))
      X_class_num.append(len(x_select))
plt.show()

plt.figure(figsize=(10,5))
plt.bar(range(0,10),X_class_num)
plt.xlabel("num of class of Fashion datasets")
plt.ylabel("num of samples")
plt.title("Distribution of Fashion Datasets")
plt.show()

"""###DATA PREPROCESSING###

**Convolutional MODEL (CNN) & Multi-Layer Perceptron (MLP)**

**Creating, Compliling and Training CNN MODEL**

**Creating, Compliling and Training MLP MODEL**
"""

# Preprocessing by reshaping and normalizing
X_train = X_train.reshape(-1, 28, 28, 1)/255.0      # The data is reshaped to fit the model input and normalized by dividing by 255.0 so the pixel values between 0 and 1 instead of 0 to 255 which helps the model learn better.
X_test = X_test.reshape(-1, 28, 28, 1)/255.0        # -1 means figuring out the right number for this dimension automatically, 1 means there's only one color channel(Grayscale)

X_train_f = X_train_f.reshape(-1, 28, 28, 1)/255.0
X_test_f = X_test_f.reshape(-1, 28, 28, 1)/255.0

# Creating CNN MODEL
def create__cnn__model():
  model = Sequential()                                                      # Sequential() creates a stack of layers.
  # 1st CNN layer & MaxPooling layer                                        # A Sequential model is created with Convolutional and MaxPooling layers, followed by flattening, hidden layer and output layers.
  model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))    # Here 32 is the number of filter and (3,3) is pixel, ReLU activation function is used to introduce non-linearity function and has a input shape of 28X28 with 1 colorscale of grayscale.
  model.add(MaxPooling2D((2,2)))                                            # Downsamples the feature map, reducing the size by taking the max value in each 2X2 value block.
  # 2nd CNN layer & MaxPooling layer
  model.add(Conv2D(32, (3,3), activation='relu'))
  model.add(MaxPooling2D(2,2))
  # Flatten layer
  model.add(Flatten())                                                      # Flattens the 2D feature maps into a 1D vector.
  # Hidden layer
  model.add(Dense(128, activation='relu'))                                  # A Fully Connected layer with 128 neurons using ReLU activation function.
  # Output layer
  model.add(Dense(10, activation='softmax'))                                # A Fully Connected layer with 10 neurons(1 for each class) using Softmax activation function for multi-class classification.

  return model

  # Compile CNN model

  # CNN MODEL MNIST Data
cnn_model_mnist = create__cnn__model()                                          # Creating CNN Model
cnn_model_mnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy'])                                   # Optimizers are used to adjust the weights in the neural network
# CNN MODEL FASHIONMNIST Data
cnn_model_fashionmnist = create__cnn__model()
cnn_model_fashionmnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy'])



  # Train the CNN MODEL on MNIST Dataset
cnn_history_mnist = cnn_model_mnist.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)   # epochs =10 means the model should go through the entire dataset for 10 times.

  # Train the CNN MODEL on FASHIONMNIST Dataset
cnn_history_fashionmnist = cnn_model_fashionmnist.fit(X_train_f, y_train_f, batch_size=64, epochs=10, validation_split=0.2)

# Creating MLP MODEL
def create__mlp__model():
  model = Sequential()
  # Flatten layer
  model.add(Flatten(input_shape=(28, 28, 1)))
  # 1st Hidden layer
  model.add(Dense(128, activation='relu'))
  # Dropout layer for regularisation
  model.add(Dropout(0.5))
  # 2nd Hidden layer
  model.add(Dense(64, activation='relu'))
  # Output layer
  model.add(Dense(10, activation='softmax'))

  return model

# Compile MLP MODEL

# MLP MODEL MNIST Data
mlp_model_mnist = create__mlp__model()
mlp_model_mnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# MLP MODEL FASHIONMNIST Data
mlp_model_fashionmnist = create__mlp__model()
mlp_model_fashionmnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train MLP MODEL MNIST Data
mlp_history_mnist = mlp_model_mnist.fit(X_train, y_train, batch_size=64, epochs=10, validation_split=0.2)

# Train MLP MODEL FashionMNIST Data
mlp_history_fashionmnist = mlp_model_fashionmnist.fit(X_train_f, y_train_f, batch_size=64, epochs=10, validation_split=0.2)

# Experimenting with hyperparameters
cnn_model_mnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_model_fashionmnist.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
cnn_history_mnist = cnn_model_mnist.fit(X_train, y_train, batch_size=64, epochs=20, validation_split=0.2)
cnn_history_fashionmnist = cnn_model_fashionmnist.fit(X_train_f, y_train_f, batch_size=64, epochs=20, validation_split=0.2)

"""## MODEL COMPARION AND EVALUATION##"""

# Evaluate and comparing models on the test dataset

# CNN MODEL
cnn_test_loss_mnist, cnn_test_acc_mnist = cnn_model_mnist.evaluate(X_test, y_test)
cnn_test_loss_fashionmnist, cnn_test_acc_fashionmnist = cnn_model_fashionmnist.evaluate(X_test_f, y_test_f)

# MLP MODEL
mlp_test_loss_mnist, mlp_test_acc_mnist = mlp_model_mnist.evaluate(X_test, y_test)
mlp_test_fashionmnist, mlp_test_acc_mnist = mlp_model_fashionmnist.evaluate(X_test_f, y_test_f)

# ACCURACY COMPARISON
print(f"CNN MODEL ACCURACY ON MNIST DATASET: {cnn_test_acc_mnist}")
print(f"CNN MODEL ACCURACY ON FASHIONMNIST DATASET: {cnn_test_acc_fashionmnist}")
print(f"MLP MODEL ACCURACY ON MNIST DATASET: {mlp_test_acc_mnist}")
print(f"MLP MODEL ACCURACY ON FASHIONMNIST DATASET: {mlp_test_acc_mnist}")

# Generate Predictions
# CNN MODEL PREDECTION
cnn_pred_mnist = np.argmax(cnn_model_mnist.predict(X_test), axis=1)
cnn_pred_fashionmnist = np.argmax(cnn_model_fashionmnist.predict(X_test_f), axis=1)
# MLP MODEL PREDECTION
mlp_pred_mnist = np.argmax(mlp_model_mnist.predict(X_test), axis=1)
mlp_pred_fashionmnist = np.argmax(mlp_model_fashionmnist.predict(X_test_f), axis=1)

# Confusion Matrix and Classification report for CNN MNIST Model
cnn_cm_mnist = confusion_matrix(y_test, cnn_pred_mnist)
cnn_cr_mnist = classification_report(y_test, cnn_pred_mnist)
sns.heatmap(cnn_cm_mnist, annot=True, fmt='d')
plt.title("CNN MODEL CONFUSION MATRIX ON MNIST DATASET")
plt.show()

# Confusion Matrix and Classification report for CNN FashionMNIST Model
cnn_cm_fashionmnist = confusion_matrix(y_test_f, cnn_pred_fashionmnist)
cnn_cr_fashionmnist = classification_report(y_test_f, cnn_pred_fashionmnist)
sns.heatmap(cnn_cm_fashionmnist, annot=True, fmt='d')
plt.title("CNN MODEL CONFUSION MATRIX ON FASHIONMNIST DATASET")
plt.show()

# Confusion Matrix and Classification report for MLP MNIST Model
mlp_cm_mnist = confusion_matrix(y_test, cnn_pred_mnist)
mlp_cr_mnist = classification_report(y_test, cnn_pred_mnist)
sns.heatmap(mlp_cm_mnist, annot=True, fmt='d')
plt.title("MLP MODEL CONFUSION MATRIX ON MNIST DATASET")
plt.show()

# Confusion Matrix and Classification report for MLP FashionMNIST MODEL
mlp_cm_fashionmnist = confusion_matrix(y_test_f, cnn_pred_fashionmnist)
mlp_cr_fashionmnist = classification_report(y_test_f, cnn_pred_fashionmnist)
sns.heatmap(mlp_cm_fashionmnist, annot=True, fmt='d')
plt.title("MLP MODEL CONFUSION MATRIX ON FASHIONMNIST DATASET")
plt.show()

# Classification report
# CNN MODEL
print(f"CNN MODEL CLASSIFICATION REPORT ON MNIST DATASET: \n {y_test, cnn_pred_mnist}")
print(f"CNN MODEL CLASSIFICATION REPORT ON FASHIONMNIST DATASET: \n {y_test_f, cnn_pred_fashionmnist}")
# MLP MODEL
print(f"MLP MODEL CLASSIFICATION REPORT ON MNIST DATASET: \n {y_test, mlp_pred_mnist}")
print(f"MLP MODEL CLASSIFICATION REPORT ON FASHIONMNIST DATASET: \n {y_test_f, mlp_pred_fashionmnist}")

"""In the confusion matrix rows represent actual values and columns represent predicted values.


*   The diagonal values having high values shows that the majority of the
    predictions are correct.
    For example : The number '973' represents the model identifies '0' as '0' (0,0) 973 times. Similarly 1133 represents the model identifies'1' as '1' (1,1) 1133 times.
*   The off diagonal elements having low values shows the number of incorrect  predictions.
     For example : The '3' in the 1st row 6th column of the 1st image shows that the model predicted the digit '7' when the actual digit was '0' 3 times.

###Data Agumentation###
"""

# Create Image Data Gerator for agumentation
datagen = ImageDataGenerator(
    rotation_range=10,                              # Rotates image by 10 degrees
    width_shift_range=0.1,                          # Shifts image horizontally by 10% of the width
    height_shift_range=0.1,                         # Shifts image vertically by 10% of the height
    zoom_range=0.1,                                 # Zooms the image
    horizontal_flip=True,                          # Flips the image horizontally
    vertical_flip=True                             # Flips the image vertically
)

# Fit the Data into the model
datagen.fit(X_train)
cnn_model_mnist.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=10)
cnn_model_fashionmnist.fit(datagen.flow(X_train, y_train, batch_size=64), epochs=10)

"""###Saving the models###"""

cnn_model_mnist.save('cnn_model_mnist.keras')
cnn_model_fashionmnist.save('cnn_model_fashionmnist.keras')
mlp_model_mnist.save('mlp_model_mnist.keras')
mlp_model_fashionmnist.save('mlp_model_fashionmnist.keras')